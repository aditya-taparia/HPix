{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_NAME = f'./'\n",
    "DATA_PATH = f'./maps'\n",
    "LOAD_PATH = f'./hpix-weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 1\n",
    "START_EPOCH = 1\n",
    "NUM_EPOCHS = 200\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS_IMG = 3\n",
    "LAMBDA_L1 = 100\n",
    "LOAD_MODEL = True\n",
    "SAVE_MODEL = True\n",
    "\n",
    "# Evaluating model\n",
    "LOAD_GEN_GLOBAL = f'{LOAD_PATH}global_gen.pth.tar'\n",
    "LOAD_GEN_LOCAL = f'{LOAD_PATH}local_gen.pth.tar'\n",
    "\n",
    "both_transform_train = A.Compose(\n",
    "    [A.Resize(286, 286),\n",
    "     A.RandomCrop(256, 256),\n",
    "     A.HorizontalFlip(p=0.5),],\n",
    "    additional_targets={\"image0\": \"image\"},\n",
    ")\n",
    "\n",
    "both_transform_test = A.Compose(\n",
    "    [A.Resize(256, 256)],\n",
    "    additional_targets={\"image0\": \"image\"},\n",
    ")\n",
    "\n",
    "transform_only_input = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[\n",
    "                    0.5, 0.5, 0.5], max_pixel_value=255.0),\n",
    "        ToTensorV2()\n",
    "    ],\n",
    ")\n",
    "\n",
    "transform_only_mask = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[\n",
    "                    0.5, 0.5, 0.5], max_pixel_value=255.0),\n",
    "        ToTensorV2()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print('=> Loading Checkpoint')\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    # Update learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def pixelLevelAcc(pred, target):\n",
    "    pred = pred[0].permute(1, 2, 0).cpu().numpy()\n",
    "    target = target[0].permute(1, 2, 0).cpu().numpy()\n",
    "    count = 0\n",
    "\n",
    "    # run a loop through each pixel\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            rd = abs(pred[i][j][0] - target[i][j][0])\n",
    "            gd = abs(pred[i][j][1] - target[i][j][1])\n",
    "            bd = abs(pred[i][j][2] - target[i][j][2])\n",
    "            if max(rd, gd, bd) <= 5:\n",
    "                count += 1\n",
    "            else:\n",
    "                count += 0\n",
    "    return count / (pred.shape[0] * pred.shape[1])\n",
    "\n",
    "def ssimAcc(pred, target):\n",
    "    pred = pred.type(torch.FloatTensor)\n",
    "    target = target.type(torch.FloatTensor)\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=255)\n",
    "    return ssim(pred, target)\n",
    "\n",
    "def psnrAcc(pred, target):\n",
    "    pred = pred.type(torch.FloatTensor)\n",
    "    target = target.type(torch.FloatTensor)\n",
    "    psnr = PeakSignalNoiseRatio()\n",
    "    return psnr(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(global_gen, local_gen, loader, deep_supervision=True):\n",
    "    global_gen.eval()\n",
    "    local_gen.eval()\n",
    "    pbar = tqdm(loader)\n",
    "    pixel_acc = 0\n",
    "    ssim_acc = 0\n",
    "    psnr_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y) in enumerate(pbar):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            if deep_supervision:\n",
    "                pred_g = global_gen(x)[6]\n",
    "            else:\n",
    "                pred_g = global_gen(x)\n",
    "            pred = local_gen(x, pred_g)\n",
    "\n",
    "            # Remove Normalization\n",
    "            pred = ((pred * 0.5 + 0.5) * 255).type(torch.IntTensor)\n",
    "            y = ((y * 0.5 + 0.5) * 255).type(torch.IntTensor)\n",
    "\n",
    "            # Calculate Pixel Accuracy and SSIM Accuracy\n",
    "            p_acc = pixelLevelAcc(pred, y)\n",
    "            s_acc = ssimAcc(pred, y)\n",
    "            ps_acc = psnrAcc(pred, y)\n",
    "            if idx < 5:\n",
    "                print(f'Pixel Accuracy: {p_acc}')\n",
    "                print(f'SSIM Accuracy: {s_acc}')\n",
    "                print(f'PSNR Accuracy: {ps_acc}')\n",
    "            pixel_acc += p_acc\n",
    "            ssim_acc += s_acc\n",
    "            psnr_acc += ps_acc\n",
    "    return pixel_acc / len(loader), ssim_acc / len(loader), psnr_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dataset loader function for validation\n",
    "class MapDatasetLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.files = os.listdir(self.root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.files[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_file)\n",
    "        image = np.array(Image.open(img_path))\n",
    "        input_img = image[:, :600, :]\n",
    "        target_img = image[:, 600:, :]\n",
    "\n",
    "        augmented = both_transform_test(image=input_img, image0=target_img)\n",
    "        input_img, target_img = augmented[\"image\"], augmented[\"image0\"]\n",
    "        input_img = transform_only_input(image=input_img)[\"image\"]\n",
    "        target_img = transform_only_mask(image=target_img)[\"image\"]\n",
    "\n",
    "        return input_img, target_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=True, act='relu', use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, 4, 2, 1,\n",
    "                            bias=False, padding_mode='reflect')\n",
    "            if downsample\n",
    "            else torch.nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            torch.nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            torch.nn.ReLU() if act == 'relu' else torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.leakyrelu = torch.nn.LeakyReLU(0.2)\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.inorm = torch.nn.InstanceNorm2d(out_channels, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.inorm(out)\n",
    "        out = self.leakyrelu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalGenerator(torch.nn.Module):\n",
    "    def __init__(self, in_channels=3, deep_supervision=False, **kwargs):\n",
    "        super().__init__()\n",
    "        features = [64, 128, 256, 512, 512, 512, 512]\n",
    "\n",
    "        self.up1 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(features[1], features[0], 4, 2, 1),\n",
    "            torch.nn.InstanceNorm2d(features[0], affine=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5)\n",
    "        )\n",
    "        self.up2 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(features[2], features[1], 4, 2, 1),\n",
    "            torch.nn.InstanceNorm2d(features[1], affine=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5)\n",
    "        )\n",
    "        self.up3 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(features[3], features[2], 4, 2, 1),\n",
    "            torch.nn.InstanceNorm2d(features[2], affine=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5)\n",
    "        )\n",
    "        self.up4 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(features[4], features[3], 4, 2, 1),\n",
    "            torch.nn.InstanceNorm2d(features[3], affine=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5)\n",
    "        )\n",
    "        self.up5 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(features[5], features[4], 4, 2, 1),\n",
    "            torch.nn.InstanceNorm2d(features[4], affine=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5)\n",
    "        )\n",
    "        self.up6 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(features[6], features[5], 4, 2, 1),\n",
    "            torch.nn.InstanceNorm2d(features[5], affine=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        self.conv0_0 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels, features[0], 4, 2, 1, padding_mode='reflect'),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv1_0 = GlobalBlock(\n",
    "            features[0], features[1], downsample=True, use_dropout=False, act='leaky')\n",
    "        self.conv2_0 = GlobalBlock(\n",
    "            features[1], features[2], downsample=True, use_dropout=False, act='leaky')\n",
    "        self.conv3_0 = GlobalBlock(\n",
    "            features[2], features[3], downsample=True, use_dropout=False, act='leaky')\n",
    "        self.conv4_0 = GlobalBlock(\n",
    "            features[3], features[4], downsample=True, use_dropout=False, act='leaky')\n",
    "        self.conv5_0 = GlobalBlock(\n",
    "            features[4], features[5], downsample=True, use_dropout=False, act='leaky')\n",
    "        self.conv6_0 = GlobalBlock(\n",
    "            features[5], features[6], downsample=True, use_dropout=False, act='leaky')\n",
    "\n",
    "        self.conv7_0 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(features[6], features[6],\n",
    "                            4, 2, 1, padding_mode='reflect'),\n",
    "        )\n",
    "        self.conv7_1 = GlobalBlock(\n",
    "            features[6], features[6], downsample=False, use_dropout=True, act='relu')\n",
    "\n",
    "        self.conv0_1 = TransitionBlock(features[0] * 2, features[0])\n",
    "        self.conv1_1 = TransitionBlock(features[1] * 2, features[1])\n",
    "        self.conv2_1 = TransitionBlock(features[2] * 2, features[2])\n",
    "        self.conv3_1 = TransitionBlock(features[3] * 2, features[3])\n",
    "        self.conv4_1 = TransitionBlock(features[4] * 2, features[4])\n",
    "        self.conv5_1 = TransitionBlock(features[5] * 2, features[5])\n",
    "        self.conv6_1 = GlobalBlock(\n",
    "            features[6] * 2, features[5], downsample=False, use_dropout=True, act='relu')\n",
    "\n",
    "        self.conv0_2 = TransitionBlock(features[0] * 3, features[0])\n",
    "        self.conv1_2 = TransitionBlock(features[1] * 3, features[1])\n",
    "        self.conv2_2 = TransitionBlock(features[2] * 3, features[2])\n",
    "        self.conv3_2 = TransitionBlock(features[3] * 3, features[3])\n",
    "        self.conv4_2 = TransitionBlock(features[4] * 3, features[4])\n",
    "        self.conv5_2 = GlobalBlock(features[5] * 3, features[4],\n",
    "                                   downsample=False, use_dropout=True, act='relu')\n",
    "\n",
    "        self.conv0_3 = TransitionBlock(features[0] * 4, features[0])\n",
    "        self.conv1_3 = TransitionBlock(features[1] * 4, features[1])\n",
    "        self.conv2_3 = TransitionBlock(features[2] * 4, features[2])\n",
    "        self.conv3_3 = TransitionBlock(features[3] * 4, features[3])\n",
    "        self.conv4_3 = GlobalBlock(features[4] * 4, features[3],\n",
    "                                   downsample=False, use_dropout=True, act='relu')\n",
    "\n",
    "        self.conv0_4 = TransitionBlock(features[0] * 5, features[0])\n",
    "        self.conv1_4 = TransitionBlock(features[1] * 5, features[1])\n",
    "        self.conv2_4 = TransitionBlock(features[2] * 5, features[2])\n",
    "        self.conv3_4 = GlobalBlock(features[3] * 5, features[2],\n",
    "                                   downsample=False, use_dropout=True, act='relu')\n",
    "\n",
    "        self.conv0_5 = TransitionBlock(features[0] * 6, features[0])\n",
    "        self.conv1_5 = TransitionBlock(features[1] * 6, features[1])\n",
    "        self.conv2_5 = GlobalBlock(features[2] * 6, features[1],\n",
    "                                   downsample=False, use_dropout=True, act='relu')\n",
    "\n",
    "        self.conv0_6 = TransitionBlock(features[0] * 7, features[0])\n",
    "        self.conv1_6 = GlobalBlock(features[1] * 7, features[0],\n",
    "                                   downsample=False, use_dropout=True, act='relu')\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            self.final1 = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(features[0], in_channels, 4, 2, 1),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "            self.final2 = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(features[0], in_channels, 4, 2, 1),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "            self.final3 = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(features[0], in_channels, 4, 2, 1),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "            self.final4 = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(features[0], in_channels, 4, 2, 1),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "            self.final5 = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(features[0], in_channels, 4, 2, 1),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "            self.final6 = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(features[0], in_channels, 4, 2, 1),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "            self.final7 = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(\n",
    "                    features[0] * 8, in_channels, 4, 2, 1),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            self.final = torch.nn.Sequential(\n",
    "                torch.nn.ConvTranspose2d(\n",
    "                    features[0] * 8, in_channels, 4, 2, 1),\n",
    "                torch.nn.Tanh()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        x1_0 = self.conv1_0(x0_0)\n",
    "        x2_0 = self.conv2_0(x1_0)\n",
    "        x3_0 = self.conv3_0(x2_0)\n",
    "        x4_0 = self.conv4_0(x3_0)\n",
    "        x5_0 = self.conv5_0(x4_0)\n",
    "        x6_0 = self.conv6_0(x5_0)\n",
    "        x7_0 = self.conv7_0(x6_0)\n",
    "        x7_1 = self.conv7_1(x7_0)\n",
    "\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up1(x1_0)], dim=1))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up2(x2_0)], dim=1))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up3(x3_0)], dim=1))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up4(x4_0)], dim=1))\n",
    "        x4_1 = self.conv4_1(torch.cat([x4_0, self.up5(x5_0)], dim=1))\n",
    "        x5_1 = self.conv5_1(torch.cat([x5_0, self.up6(x6_0)], dim=1))\n",
    "        x6_1 = self.conv6_1(torch.cat([x6_0, x7_1], dim=1))\n",
    "\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up1(x1_1)], dim=1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up2(x2_1)], dim=1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up3(x3_1)], dim=1))\n",
    "        x3_2 = self.conv3_2(torch.cat([x3_0, x3_1, self.up4(x4_1)], dim=1))\n",
    "        x4_2 = self.conv4_2(torch.cat([x4_0, x4_1, self.up5(x5_1)], dim=1))\n",
    "        x5_2 = self.conv5_2(torch.cat([x5_0, x5_1, x6_1], dim=1))\n",
    "\n",
    "        x0_3 = self.conv0_3(\n",
    "            torch.cat([x0_0, x0_1, x0_2, self.up1(x1_2)], dim=1))\n",
    "        x1_3 = self.conv1_3(\n",
    "            torch.cat([x1_0, x1_1, x1_2, self.up2(x2_2)], dim=1))\n",
    "        x2_3 = self.conv2_3(\n",
    "            torch.cat([x2_0, x2_1, x2_2, self.up3(x3_2)], dim=1))\n",
    "        x3_3 = self.conv3_3(\n",
    "            torch.cat([x3_0, x3_1, x3_2, self.up4(x4_2)], dim=1))\n",
    "        x4_3 = self.conv4_3(torch.cat([x4_0, x4_1, x4_2, x5_2], dim=1))\n",
    "\n",
    "        x0_4 = self.conv0_4(\n",
    "            torch.cat([x0_0, x0_1, x0_2, x0_3, self.up1(x1_3)], dim=1))\n",
    "        x1_4 = self.conv1_4(\n",
    "            torch.cat([x1_0, x1_1, x1_2, x1_3, self.up2(x2_3)], dim=1))\n",
    "        x2_4 = self.conv2_4(\n",
    "            torch.cat([x2_0, x2_1, x2_2, x2_3, self.up3(x3_3)], dim=1))\n",
    "        x3_4 = self.conv3_4(torch.cat([x3_0, x3_1, x3_2, x3_3, x4_3], dim=1))\n",
    "\n",
    "        x0_5 = self.conv0_5(\n",
    "            torch.cat([x0_0, x0_1, x0_2, x0_3, x0_4, self.up1(x1_4)], dim=1))\n",
    "        x1_5 = self.conv1_5(\n",
    "            torch.cat([x1_0, x1_1, x1_2, x1_3, x1_4, self.up2(x2_4)], dim=1))\n",
    "        x2_5 = self.conv2_5(\n",
    "            torch.cat([x2_0, x2_1, x2_2, x2_3, x2_4, x3_4], dim=1))\n",
    "\n",
    "        x0_6 = self.conv0_6(\n",
    "            torch.cat([x0_0, x0_1, x0_2, x0_3, x0_4, x0_5, self.up1(x1_5)], dim=1))\n",
    "        x1_6 = self.conv1_6(\n",
    "            torch.cat([x1_0, x1_1, x1_2, x1_3, x1_4, x1_5, x2_5], dim=1))\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            o1 = self.final1(x0_1)\n",
    "            o2 = self.final2(x0_2)\n",
    "            o3 = self.final3(x0_3)\n",
    "            o4 = self.final4(x0_4)\n",
    "            o5 = self.final5(x0_5)\n",
    "            o6 = self.final6(x0_6)\n",
    "            o7 = self.final7(\n",
    "                torch.cat([x0_0, x0_1, x0_2, x0_3, x0_4, x0_5, x0_6, x1_6], dim=1))\n",
    "\n",
    "            return [o1, o2, o3, o4, o5, o6, o7]\n",
    "        else:\n",
    "            final = self.final(\n",
    "                torch.cat([x0_0, x0_1, x0_2, x0_3, x0_4, x0_5, x0_6, x1_6], dim=1))\n",
    "\n",
    "            return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act='relu', use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, 4, 2, 1,\n",
    "                            bias=False, padding_mode='reflect')\n",
    "            if down\n",
    "            else torch.nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            torch.nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            torch.nn.ReLU() if act == 'relu' else torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalGenerator(torch.nn.Module):\n",
    "    def __init__(self, in_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels*2, features, 4, 2,\n",
    "                            1, padding_mode='reflect'),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )  # 128\n",
    "        self.down1 = LocalBlock(features, features * 2, down=True,\n",
    "                                use_dropout=False, act='leaky')  # 64\n",
    "        self.down2 = LocalBlock(features * 2, features * 4,\n",
    "                                down=True, use_dropout=False, act='leaky')  # 32\n",
    "        self.down3 = LocalBlock(features * 4, features * 8,\n",
    "                                down=True, use_dropout=False, act='leaky')  # 16\n",
    "        self.down4 = LocalBlock(features * 8, features * 8,\n",
    "                                down=True, use_dropout=False, act='leaky')  # 8\n",
    "        self.down5 = LocalBlock(features * 8, features * 8,\n",
    "                                down=True, use_dropout=False, act='leaky')  # 4\n",
    "        self.down6 = LocalBlock(features * 8, features * 8,\n",
    "                                down=True, use_dropout=False, act='leaky')  # 2\n",
    "\n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(features * 8, features * 8, 4, 2,\n",
    "                            1, padding_mode='reflect'),  # 1\n",
    "        )\n",
    "\n",
    "        self.up1 = LocalBlock(features * 8, features * 8, down=False,\n",
    "                              use_dropout=True, act='relu')  # 4\n",
    "        self.up2 = LocalBlock(features * 8 * 2, features * 8,\n",
    "                              down=False, use_dropout=True, act='relu')  # 8\n",
    "        self.up3 = LocalBlock(features * 8 * 2, features * 8,\n",
    "                              down=False, use_dropout=True, act='relu')  # 16\n",
    "        self.up4 = LocalBlock(features * 8 * 2, features * 8,\n",
    "                              down=False, use_dropout=False, act='relu')  # 32\n",
    "        self.up5 = LocalBlock(features * 8 * 2, features * 4,\n",
    "                              down=False, use_dropout=False, act='relu')  # 64\n",
    "        self.up6 = LocalBlock(features * 4 * 2, features * 2,\n",
    "                              down=False, use_dropout=False, act='relu')  # 128\n",
    "        self.up7 = LocalBlock(features * 2 * 2, features, down=False,\n",
    "                              use_dropout=False, act='relu')  # 256\n",
    "\n",
    "        self.final_up = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(features * 2, in_channels, 4, 2, 1),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
    "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
    "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
    "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
    "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
    "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
    "        return self.final_up(torch.cat([up7, d1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global_gen = GlobalGenerator(\n",
    "        in_channels=3, deep_supervision=True).to(DEVICE)\n",
    "    local_gen = LocalGenerator(in_channels=3).to(DEVICE)\n",
    "\n",
    "    opt_gen_global = torch.optim.Adam(\n",
    "        global_gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "    opt_gen_local = torch.optim.Adam(\n",
    "        local_gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            LOAD_GEN_GLOBAL,\n",
    "            global_gen,\n",
    "            opt_gen_global,\n",
    "            LEARNING_RATE\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            LOAD_GEN_LOCAL,\n",
    "            local_gen,\n",
    "            opt_gen_local,\n",
    "            LEARNING_RATE\n",
    "        )\n",
    "\n",
    "    val_dataset_path = f'{DATA_PATH}maps/val'\n",
    "    val_dataset = MapDatasetLoader(root_dir=val_dataset_path)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    pixel_level_accuracy, ssim_accuracy, psnr_accuracy = evaluate(global_gen, local_gen, val_loader)\n",
    "    \n",
    "    print(f'Average Pixel Level Accuracy: {pixel_level_accuracy}')\n",
    "    print(f'Average SSIM Accuracy: {ssim_accuracy}')\n",
    "    print(f'Average PSNR Accuracy: {psnr_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
